{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Lambda, Input, Flatten, BatchNormalization\n",
    "from keras.models import load_model, Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUTS_FNAME   = \"lfw_datasets_and_models.zip\"\n",
    "\n",
    "PATH_INPUTS_FNAME     = \"./lfw_datasets_and_models.zip\" \n",
    "PATH_INPUTS           = \"./test/lfw_datasets_and_models\"\n",
    "\n",
    "PATH_DATASET_BASE     = PATH_INPUTS + \"/datasets\"\n",
    "\n",
    "PATH_DATASET_BASE_MASKED   = PATH_DATASET_BASE + \"/masked\"\n",
    "PATH_DATASET_BASE_UNMASKED = PATH_DATASET_BASE + \"/unmasked\"\n",
    "\n",
    "PATH_DATASET_MASKED_TRAIN = PATH_DATASET_BASE_MASKED + \"/train/\"\n",
    "PATH_DATASET_MASKED_VAL   = PATH_DATASET_BASE_MASKED + \"/validation/\"\n",
    "PATH_DATASET_MASKED_TEST  = PATH_DATASET_BASE_MASKED + \"/test/\"\n",
    "\n",
    "PATH_DATASET_UNMASKED_TRAIN = PATH_DATASET_BASE_UNMASKED + \"/train/\"\n",
    "PATH_DATASET_UNMASKED_VAL   = PATH_DATASET_BASE_UNMASKED + \"/validation/\"\n",
    "PATH_DATASET_UNMASKED_TEST  = PATH_DATASET_BASE_UNMASKED + \"/test/\"\n",
    "\n",
    "PATH_TRAIN_RESNET = PATH_INPUTS + '/models/resnet/retrained/'\n",
    "PATH_TRAIN_FACENET = PATH_INPUTS + '/models/facenet/retrained/'\n",
    "PATH_TRAIN_DATASET = PATH_INPUTS + '/training'\n",
    "PATH_TRAIN_ANCHOR_DATASET = PATH_TRAIN_DATASET + '/anchor/'\n",
    "PATH_TRAIN_POSITIVE_DATASET = PATH_TRAIN_DATASET + '/positive/'\n",
    "\n",
    "PATH_FACENET_KERAS_H5 = PATH_INPUTS + \"/models/facenet/pretrained/model/facenet_keras.h5\"\n",
    "\n",
    "TRIPLET_LOSS_MARGIN = 2\n",
    "\n",
    "IMAGE_INPUT_SIZE = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_zipfile(filename: str, extract_dirname: str, extract_path: str):\n",
    "    # Extract the inputs from the zip file.\n",
    "    if (not os.path.isdir(extract_dirname)):\n",
    "        print(\"[INFO] Extracting from '{}' to '../'...\".format(filename), end=\" \")\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"DONE.\")\n",
    "    else:\n",
    "        print(\"[INFO] Directory '{}' exists.\".format(extract_dirname))\n",
    "\n",
    "#extract_zipfile(PATH_INPUTS_FNAME, PATH_INPUTS, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [Retraing]\n",
    "def triplet_loss(inputs, dist='euclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, TRIPLET_LOSS_MARGIN + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(1 + K.exp(loss))\n",
    "        \n",
    "    returned_loss = K.mean(loss)\n",
    "    return returned_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "# Used when compiling the siamese network\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)  # This is actually just returning y_pred bcs\n",
    "                                        # K.mean has already been called in the triplet_loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "def get_siamese_from_facenet():\n",
    "    model = load_model(PATH_FACENET_KERAS_H5)\n",
    "    print(len(model.layers))\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    #model.summary()\n",
    "\n",
    "    layers_count = len(model.layers)\n",
    "    for i in range(layers_count - 10):\n",
    "        layer = model.layers[i]\n",
    "        if i < layers_count//2:\n",
    "            layer.trainable = False # Freeze first half of layers.\n",
    "        elif layer.trainable and not layer.name.endswith(\"BatchNorm\"):\n",
    "            layer.trainable = False # Leave all BatchNorm layers to retrain.\n",
    "\n",
    "    last_layer = model.layers[layers_count - 1]\n",
    "    assert last_layer.trainable == True # Ensure last layer to retrain.\n",
    "\n",
    "    # Define the siamese facenet network\n",
    "    image_shape = (IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE, 3)\n",
    "\n",
    "    model_out = last_layer.output\n",
    "    model_out = Dense(128, activation = 'relu',  name = 'model_out')(model_out)\n",
    "    model_out = BatchNormalization(axis = 1, epsilon=0.00001, name = 'BatchNorm_last')(model_out)\n",
    "    model_out = Lambda(lambda  x: K.l2_normalize(x, axis = 1))(model_out)\n",
    "\n",
    "    new_model = Model(inputs=model.input, outputs=model_out)\n",
    "\n",
    "    anchor_input = Input(shape=image_shape, name ='anchor_input')\n",
    "    pos_input = Input(shape=image_shape, name ='pos_input')\n",
    "    neg_input = Input(shape=image_shape, name ='neg_input')\n",
    "\n",
    "    encoding_anchor = new_model(anchor_input)\n",
    "    encoding_pos = new_model(pos_input)\n",
    "    encoding_neg = new_model(neg_input)\n",
    "\n",
    "    loss = Lambda(triplet_loss)([encoding_anchor, encoding_pos, encoding_neg])\n",
    "\n",
    "    siamese_facenet = Model(inputs  = [anchor_input, pos_input, neg_input], outputs = loss)\n",
    "    siamese_facenet.compile(optimizer = Adam(lr = .01, clipnorm = 1.), loss = identity_loss)\n",
    "    siamese_facenet.summary()\n",
    "    return new_model, siamese_facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_TARGET_SHAPE = (IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE)\n",
    "\n",
    "def extract_face(image_path : str):\n",
    "    # load image from file\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize(IMAGE_TARGET_SHAPE)\n",
    "    img_array = np.asarray(img)\n",
    "    img_array = img_array.astype('float32')\n",
    "    # Standardization\n",
    "    mean, std = img_array.mean(), img_array.std()\n",
    "    img_array = (img_array - mean) / std\n",
    "    # Expand 3 dimension to 4 dimension.\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def create_triplets(images_path :str, num_triplets_required = 50000):\n",
    "    images_subdir = []\n",
    "    for subdir in os.listdir(images_path):\n",
    "        if len(images_subdir) == num_triplets_required:\n",
    "            break\n",
    "        filenames = os.listdir(images_path + subdir)\n",
    "        \n",
    "        # Skip directory with single image.\n",
    "        if len(filenames) < 2:\n",
    "            continue\n",
    "        images_subdir.append(subdir)\n",
    "\n",
    "    print(\"Total pairs found : \" + str(len(images_subdir)))\n",
    "    image_input_shape = (len(images_subdir), IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE, 3)\n",
    "    \n",
    "    anchor_imgs = np.empty(image_input_shape)\n",
    "    pos_imgs = np.empty(image_input_shape)\n",
    "    neg_imgs = np.empty(image_input_shape)\n",
    "    for idx, subdir in enumerate(images_subdir):\n",
    "        filenames = os.listdir(images_path + subdir)\n",
    "        assert len(filenames) > 1\n",
    "        image_path = images_path + subdir + \"/\" + filenames[0]\n",
    "        anchor_imgs[idx] = extract_face(image_path)\n",
    "\n",
    "        image_path = images_path + subdir + \"/\" + filenames[1]\n",
    "        pos_imgs[idx] = extract_face(image_path)\n",
    "\n",
    "    # Rotate pos_imgs by 1 to make them negative for other faces.\n",
    "    neg_imgs = np.roll(pos_imgs, 1, axis = 0)\n",
    "    return (anchor_imgs, pos_imgs, neg_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unmasked_and_masked_triplets(unmasked_images_path :str, masked_images_path :str, \n",
    "                                        num_triplets_required = 50000):\n",
    "\n",
    "    masked_dict = {}\n",
    "    unmasked_path = []\n",
    "    \n",
    "    # Create pairs (subdir, filename) for unmasked images.\n",
    "    for subdir in os.listdir(unmasked_images_path):\n",
    "        filenames = os.listdir(unmasked_images_path + subdir)\n",
    "        filename = unmasked_images_path + subdir + \"/\" + filenames[0]\n",
    "        unmasked_path.append((subdir, filename))\n",
    "\n",
    "    # Create dictionary {subdir : filename} for maksed images to join with unmasked.\n",
    "    for subdir in os.listdir(masked_images_path):\n",
    "        filenames = os.listdir(masked_images_path + subdir)\n",
    "        filename = masked_images_path + subdir + \"/\" + filenames[0]\n",
    "        masked_dict[subdir] = filename\n",
    "\n",
    "    image_pairs = []\n",
    "    for i in range(len(unmasked_path)):\n",
    "        if len(image_pairs) == num_triplets_required:\n",
    "            break\n",
    "        anchor_name, anchor_path = unmasked_path[i]\n",
    "        if anchor_name not in masked_dict:\n",
    "            continue\n",
    "        pos_path = masked_dict[anchor_name]\n",
    "        image_pairs.append((anchor_path, pos_path))\n",
    "        \n",
    "    print(\"Total pairs found : \" + str(len(image_pairs)))\n",
    "    image_input_shape = (len(image_pairs), IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE, 3)\n",
    "    \n",
    "    anchor_imgs = np.empty(image_input_shape)\n",
    "    pos_imgs = np.empty(image_input_shape)\n",
    "    neg_imgs = np.empty(image_input_shape)\n",
    "    for idx, image_pair in enumerate(image_pairs):\n",
    "        anchor_imgs[idx] = extract_face(image_pair[0])\n",
    "        pos_imgs[idx] = extract_face(image_pair[1])\n",
    "\n",
    "    # Rotate pos_imgs by 1 to make them negative for other faces.\n",
    "    neg_imgs = np.roll(pos_imgs, 1, axis = 0)\n",
    "    return (anchor_imgs, pos_imgs, neg_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs found : 1389\n",
      "Total pairs found : 600\n",
      "Total pairs found : 5721\n",
      "(7710, 160, 160, 3)\n",
      "(7710, 160, 160, 3)\n",
      "(7710, 160, 160, 3)\n",
      "[-1.88252294 -1.88252294 -1.88252294]\n",
      "[-1.88252294 -1.88252294 -1.88252294]\n"
     ]
    }
   ],
   "source": [
    "anchor1, pos1, neg1 = create_triplets(PATH_DATASET_UNMASKED_TRAIN)\n",
    "anchor2, pos2, neg2 = create_triplets(PATH_DATASET_MASKED_TRAIN)\n",
    "anchor3, pos3, neg3 = create_unmasked_and_masked_triplets(PATH_DATASET_UNMASKED_TRAIN, PATH_DATASET_MASKED_TRAIN)\n",
    "\n",
    "anchor_images = np.concatenate((anchor1, anchor2, anchor3), axis = 0)\n",
    "pos_images = np.concatenate((pos1, pos2, pos3), axis = 0)\n",
    "neg_images = np.concatenate((neg1, neg2, neg3), axis = 0)\n",
    "\n",
    "print(anchor_images.shape)\n",
    "print(pos_images.shape)\n",
    "print(neg_images.shape)\n",
    "\n",
    "# Ensure neg_images are rotated version of pos_images\n",
    "print(pos_images[0][0][0])\n",
    "print(neg_images[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7710\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "426\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input (InputLayer)          (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neg_input (InputLayer)          (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          22808400    anchor_input[0][0]               \n",
      "                                                                 pos_input[0][0]                  \n",
      "                                                                 neg_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               ()                   0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,808,400\n",
      "Trainable params: 1,039,744\n",
      "Non-trainable params: 21,768,656\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "training_loss = []\n",
    "z = np.zeros(len(anchor_images))\n",
    "print(len(z))\n",
    "\n",
    "new_model, siamese_model = get_siamese_from_facenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "7710/7710 [==============================] - 286s 37ms/step - loss: 1.4991\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "facenet_encoding_input (Inpu (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128)               22808400  \n",
      "=================================================================\n",
      "Total params: 22,808,400\n",
      "Trainable params: 1,039,744\n",
      "Non-trainable params: 21,768,656\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "7710/7710 [==============================] - 223s 29ms/step - loss: 1.3191\n",
      "Epoch 1/1\n",
      "7710/7710 [==============================] - 222s 29ms/step - loss: 1.2670\n",
      "Epoch 1/1\n",
      "7710/7710 [==============================] - 221s 29ms/step - loss: 1.2240\n",
      "Epoch 1/1\n",
      "7710/7710 [==============================] - 222s 29ms/step - loss: 1.1929\n",
      "Epoch 1/1\n",
      "2304/7710 [=======>......................] - ETA: 2:38 - loss: 1.1973"
     ]
    }
   ],
   "source": [
    "EPOCHS_COUNT = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for epoch in range(EPOCHS_COUNT):\n",
    "    siamese_model.fit(x=[anchor_images, pos_images, neg_images], \n",
    "                    y=z, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=1, \n",
    "                    verbose=1, \n",
    "                    callbacks=None, \n",
    "                    validation_split=0.0, \n",
    "                    validation_data=None, \n",
    "                    shuffle=True, \n",
    "                    class_weight=None, \n",
    "                    sample_weight=None, \n",
    "                    initial_epoch=0, \n",
    "                    steps_per_epoch=None, \n",
    "                    validation_steps=None)\n",
    "    training_loss.append(siamese_model.history.history['loss'])\n",
    "    \n",
    "    # Rotate negatives in triplets for next epoch.\n",
    "    neg1 = np.roll(neg1, 1, axis = 0)\n",
    "    neg2 = np.roll(neg2, 1, axis = 0)\n",
    "    neg3 = np.roll(neg3, 1, axis = 0)\n",
    "    neg_images = np.concatenate((neg1, neg2, neg3), axis = 0)\n",
    "    \n",
    "    if (epoch % 5 == 0 and training_loss[-1][0] > 0):\n",
    "        # Create and save the Encoding Network to use in predictions.\n",
    "        encoding_input = Input(shape=(IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE, 3), name='facenet_encoding_input')\n",
    "        encoding_output = new_model(encoding_input)\n",
    "        encoding_facenet = Model(inputs  = encoding_input, outputs = encoding_output)\n",
    "        weights = siamese_model.get_layer('model_1').get_weights()\n",
    "        encoding_facenet.get_layer('model_1').set_weights(weights)\n",
    "        encoding_facenet.summary()\n",
    "        \n",
    "        # Save the Encoding Network architecture\n",
    "        encoding_model_json = encoding_facenet.to_json()\n",
    "        with open(PATH_TRAIN_FACENET + \"/encoding_facenet_arch.json\", \"w\") as json_file:\n",
    "            json_file.write(encoding_model_json)\n",
    "        # Save the Encoding Network model weights    \n",
    "        encoding_facenet.save_weights(PATH_TRAIN_FACENET + '/encoding_facenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "title = 'Triplet Loss'\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training completed so save the model architecture and weights.\n",
    "# We can save the Siamese FaceNet Network architecture.\n",
    "# siamese_model_json = siamese_facenet.to_json()\n",
    "# with open(PATH_TRAIN_FACENET + \"/siamese_facenet_arch.json\", \"w\") as json_file:\n",
    "#     json_file.write(siamese_model_json)\n",
    "# # save the Siamese Network model weights\n",
    "# siamese_facenet.save_weights(PATH_TRAIN_FACENET + \"/siamese_facenet_weights.h5\")\n",
    "\n",
    "# Create and save the Encoding Network to use in predictions.\n",
    "# encoding_input = Input(shape=(IMAGE_INPUT_SIZE, IMAGE_INPUT_SIZE, 3), name='facenet_encoding_input')\n",
    "# encoding_output = new_model(encoding_input)\n",
    "# encoding_facenet = Model(inputs  = encoding_input, outputs = encoding_output)\n",
    "# weights = siamese_model.get_layer('model_1').get_weights()\n",
    "# encoding_facenet.get_layer('model_1').set_weights(weights)\n",
    "# encoding_facenet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the Encoding Network architecture\n",
    "# encoding_model_json = encoding_facenet.to_json()\n",
    "# with open(PATH_TRAIN_FACENET + \"/encoding_facenet_arch.json\", \"w\") as json_file:\n",
    "#     json_file.write(encoding_model_json)\n",
    "# # Save the Encoding Network model weights    \n",
    "# encoding_facenet.save_weights(PATH_TRAIN_FACENET + '/encoding_facenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"[INFO] Loading Facenet model...\")\n",
    "# with open(PATH_TRAIN_FACENET + '/encoding_facenet_arch.json','r') as f:\n",
    "#     model_json = f.read()\n",
    "\n",
    "# facenet_model = model_from_json(model_json)\n",
    "# facenet_model.load_weights(PATH_TRAIN_FACENET + '/encoding_facenet_weights.h5')\n",
    "# #facenet_model = load_model(PATH_FACENET_KERAS_H5)\n",
    "# print('[INFO] Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# positive_encodings = []\n",
    "# for i in range(50):\n",
    "#     encoding = encoding_facenet.predict([pos_images[i:i+1]], batch_size = 1, verbose = 0)\n",
    "#     positive_encodings.append(encoding)\n",
    "\n",
    "# for i in range(50):\n",
    "#     anchor_encoding = encoding_facenet.predict([anchor_images[i:i+1]], batch_size = 1, verbose = 0)\n",
    "#     min_distance = 10000\n",
    "#     min_index = -1\n",
    "#     for j in range(len(positive_encodings)):\n",
    "#         if i == j:\n",
    "#             continue\n",
    "#         distance = np.linalg.norm(anchor_encoding - positive_encodings[j])\n",
    "#         if distance < min_distance:\n",
    "#             min_distance = distance\n",
    "#             min_index = j\n",
    "    \n",
    "#     pos_distance = np.linalg.norm(anchor_encoding - positive_encodings[i])\n",
    "#     if (pos_distance <= min_distance):\n",
    "#         print(str(i) + \" postive distance   : \" + str(pos_distance))\n",
    "#         print(str(min_index) + \" negative distance : \" + str(min_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
