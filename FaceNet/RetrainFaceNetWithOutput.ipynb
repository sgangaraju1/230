{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Lambda, Input\n",
    "from keras.models import load_model, Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_FNAME   = \"lfw_datasets_and_models.zip\"\n",
    "\n",
    "PATH_INPUTS_FNAME     = \"./lfw_datasets_and_models.zip\" \n",
    "PATH_INPUTS           = \"./test/lfw_datasets_and_models\"\n",
    "\n",
    "PATH_DATASET_BASE     = PATH_INPUTS + \"/datasets\"\n",
    "\n",
    "PATH_DATASET_BASE_MASKED   = PATH_DATASET_BASE + \"/masked\"\n",
    "PATH_DATASET_BASE_UNMASKED = PATH_DATASET_BASE + \"/unmasked\"\n",
    "\n",
    "PATH_DATASET_MASKED_TRAIN = PATH_DATASET_BASE_MASKED + \"/train/\"\n",
    "PATH_DATASET_MASKED_VAL   = PATH_DATASET_BASE_MASKED + \"/validation/\"\n",
    "PATH_DATASET_MASKED_TEST  = PATH_DATASET_BASE_MASKED + \"/test/\"\n",
    "\n",
    "PATH_DATASET_UNMASKED_TRAIN = PATH_DATASET_BASE_UNMASKED + \"/train/\"\n",
    "PATH_DATASET_UNMASKED_VAL   = PATH_DATASET_BASE_UNMASKED + \"/validation/\"\n",
    "PATH_DATASET_UNMASKED_TEST  = PATH_DATASET_BASE_UNMASKED + \"/test/\"\n",
    "\n",
    "PATH_TRAIN_RESNET = PATH_INPUTS + '/models/resnet'\n",
    "PATH_TRAIN_FACENET = PATH_INPUTS + '/models/facenet'\n",
    "\n",
    "PATH_FACENET_KERAS_H5 = PATH_INPUTS + \"/models/facenet/keras-facenet/model/facenet_keras.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zipfile(filename: str, extract_dirname: str, extract_path: str):\n",
    "    # Extract the inputs from the zip file.\n",
    "    if (not os.path.isdir(extract_dirname)):\n",
    "        print(\"[INFO] Extracting from '{}' to '../'...\".format(filename), end=\" \")\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"DONE.\")\n",
    "    else:\n",
    "        print(\"[INFO] Directory '{}' exists.\".format(extract_dirname))\n",
    "\n",
    "#extract_zipfile(PATH_INPUTS_FNAME, PATH_INPUTS, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5721\n",
      "5749\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "# [Retraining]\n",
    "TRAINING_IMAGES_COUNT = 265\n",
    "\n",
    "masked_path = []\n",
    "masked_dict = {}\n",
    "unmasked_path = []\n",
    "training_path = []\n",
    "for subdir in os.listdir(PATH_DATASET_MASKED_TRAIN):\n",
    "    filenames = os.listdir(PATH_DATASET_MASKED_TRAIN + subdir)\n",
    "    filename = PATH_DATASET_MASKED_TRAIN + subdir + \"/\" + filenames[0]\n",
    "    masked_path.append((subdir, filename))\n",
    "    masked_dict[subdir] = filename\n",
    "\n",
    "for subdir in os.listdir(PATH_DATASET_UNMASKED_TRAIN):\n",
    "    filenames = os.listdir(PATH_DATASET_UNMASKED_TRAIN + subdir)\n",
    "    filename = PATH_DATASET_UNMASKED_TRAIN + subdir + \"/\" + filenames[0]\n",
    "    unmasked_path.append((subdir, filename))\n",
    "\n",
    "print(len(masked_path))\n",
    "print(len(unmasked_path))\n",
    "\n",
    "masked_count = len(masked_path)\n",
    "unmasked_count = len(unmasked_path)\n",
    "neg = np.random.randint(masked_count, size=unmasked_count)\n",
    "for i in range(TRAINING_IMAGES_COUNT):\n",
    "    a_name, a_path = unmasked_path[i]\n",
    "    if a_name not in masked_dict:\n",
    "        continue\n",
    "    pos_path = masked_dict[a_name]\n",
    "    if (a_name != masked_path[neg[i]][0]):\n",
    "        neg_path = masked_path[neg[i]][1]\n",
    "    else:\n",
    "        neg_path = masked_path[neg[i+1]][1]\n",
    "    training_path.append((a_path, pos_path, neg_path))\n",
    "        \n",
    "print(len(training_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraing]\n",
    "def triplet_loss(inputs, dist='euclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, 1.8 + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(1 + K.exp(loss))\n",
    "        \n",
    "    returned_loss = K.mean(loss)\n",
    "    return returned_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "# Used when compiling the siamese network\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)  # This is actually just returning y_pred bcs\n",
    "                                        # K.mean has already been called in the triplet_loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "426\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
      "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
      "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
      "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
      "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
      "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
      "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
      "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
      "                                                                 Block17_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
      "                                                                 Block17_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
      "                                                                 Block17_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
      "                                                                 Block17_6_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
      "                                                                 Block17_7_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
      "                                                                 Block17_8_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
      "                                                                 Block17_9_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
      "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
      "                                                                 Block17_10_Conv2d_1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
      "                                                                 Block8_1_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
      "                                                                 Block8_2_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
      "                                                                 Block8_3_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
      "                                                                 Block8_4_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
      "                                                                 Block8_5_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
      "                                                                 Block8_6_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 22,578,384\n",
      "Trainable params: 22,549,808\n",
      "Non-trainable params: 28,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# [Retraining]\n",
    "model = load_model(PATH_FACENET_KERAS_H5)\n",
    "print(len(model.layers))\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_count = len(model.layers)\n",
    "for i in range(layers_count):\n",
    "    layer = model.layers[i]\n",
    "    if i < layers_count//2:\n",
    "        layer.trainable = False # Freeze first half of layers.\n",
    "    elif layer.trainable and not layer.name.endswith(\"BatchNorm\"):\n",
    "        layer.trainable = False # Leave all BatchNorm layers to retrain.\n",
    "\n",
    "last_layer = model.layers[layers_count - 1]\n",
    "last_layer.trainable = True # Mark last layer to retrain.\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    print(layer.name + \" : \" + str(layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input (InputLayer)          (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neg_input (InputLayer)          (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          22807888    anchor_input[0][0]               \n",
      "                                                                 pos_input[0][0]                  \n",
      "                                                                 neg_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               ()                   0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,807,888\n",
      "Trainable params: 238,976\n",
      "Non-trainable params: 22,568,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# [Retraining]\n",
    "# Define the siamese facenet network\n",
    "\n",
    "image_shape = (160, 160, 3)\n",
    "\n",
    "x = last_layer.output\n",
    "model_out = Dense(128, activation='relu',  name='model_out')(x)\n",
    "model_out = Lambda(lambda  x: K.l2_normalize(x, axis=-1))(model_out)\n",
    "\n",
    "new_model = Model(inputs=model.input, outputs=model_out)\n",
    "\n",
    "anchor_input = Input(shape=image_shape, name='anchor_input')\n",
    "pos_input = Input(shape=image_shape, name='pos_input')\n",
    "neg_input = Input(shape=image_shape, name='neg_input')\n",
    "\n",
    "encoding_anchor = new_model(anchor_input)\n",
    "encoding_pos = new_model(pos_input)\n",
    "encoding_neg = new_model(neg_input)\n",
    "\n",
    "loss = Lambda(triplet_loss)([encoding_anchor, encoding_pos, encoding_neg])\n",
    "\n",
    "siamese_facenet = Model(inputs  = [anchor_input, pos_input, neg_input], outputs = loss)\n",
    "siamese_facenet.compile(optimizer=Adam(lr=.05, clipnorm=1.), loss=identity_loss)\n",
    "siamese_facenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      " - 59s - loss: 1.7598\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7953\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7830\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7906\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7976\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7718\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.7488\n",
      "Epoch : 0 Time taken : 73.58878183364868\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.6532\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3124\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3597\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3968\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.4761\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.5336\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.5585\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.5267\n",
      "Epoch : 1 Time taken : 9.739009380340576\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.4897\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1537\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.2180\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1946\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3118\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3479\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3896\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3429\n",
      "Epoch : 2 Time taken : 8.908381462097168\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.3256\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0232\n",
      "Epoch 1/1\n",
      " - 2s - loss: 1.0901\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0057\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1618\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1761\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.2173\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1646\n",
      "Epoch : 3 Time taken : 10.605709314346313\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.1650\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9011\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9649\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8389\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0220\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0058\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0644\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0224\n",
      "Epoch : 4 Time taken : 9.110747337341309\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0265\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7711\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8407\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7857\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9096\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8840\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9195\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8895\n",
      "Epoch : 5 Time taken : 9.030072212219238\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9159\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7741\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7535\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6942\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8181\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8800\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9466\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8611\n",
      "Epoch : 6 Time taken : 9.018891334533691\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8467\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8000\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6939\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6642\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7899\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7940\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8477\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7724\n",
      "Epoch : 7 Time taken : 9.156587362289429\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7656\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6901\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6250\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6086\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7738\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7000\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7457\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7015\n",
      "Epoch : 8 Time taken : 9.088588953018188\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6893\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6390\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5861\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5640\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6755\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6243\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6310\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6469\n",
      "Epoch : 9 Time taken : 9.072810888290405\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6648\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6244\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5752\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5472\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6859\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6144\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6434\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6281\n",
      "Epoch : 10 Time taken : 9.10208773612976\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6258\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5757\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5240\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5325\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6028\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6232\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5574\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6102\n",
      "Epoch : 11 Time taken : 9.708409547805786\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6404\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5422\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5140\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5214\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6130\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5695\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5691\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5890\n",
      "Epoch : 12 Time taken : 9.723097801208496\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6167\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5591\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5334\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5194\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5691\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5465\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5685\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5406\n",
      "Epoch : 13 Time taken : 9.53976845741272\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5514\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5213\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5056\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5016\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5676\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5423\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5317\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6037\n",
      "Epoch : 14 Time taken : 9.267629861831665\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5788\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5371\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5212\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5153\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5638\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5255\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5415\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5538\n",
      "Epoch : 15 Time taken : 9.10348916053772\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5642\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5217\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4959\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4898\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5479\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5034\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5244\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5369\n",
      "Epoch : 16 Time taken : 9.11105751991272\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5295\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5007\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4797\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5099\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5736\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5666\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5404\n",
      "Epoch : 17 Time taken : 9.100488662719727\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5371\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4701\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4906\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4724\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5286\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5134\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5124\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5496\n",
      "Epoch : 18 Time taken : 9.269275188446045\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4982\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4768\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4774\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4844\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5509\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5342\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5056\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5750\n",
      "Epoch : 19 Time taken : 9.061346292495728\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5219\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4888\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4828\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5022\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6049\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5324\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5346\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5532\n",
      "Epoch : 20 Time taken : 9.14647626876831\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5334\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4858\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4774\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4866\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5126\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4847\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5078\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4788\n",
      "Epoch : 21 Time taken : 9.184208631515503\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5645\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4675\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4712\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4643\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.5319\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.4913\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5135\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5607\n",
      "Epoch : 22 Time taken : 10.946353197097778\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5227\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4644\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4685\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4881\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5120\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5674\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4826\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4959\n",
      "Epoch : 23 Time taken : 9.476625442504883\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5338\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4650\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4532\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5104\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5415\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4807\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4889\n",
      "Epoch : 24 Time taken : 9.865105628967285\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_COUNT = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "image_input_shape = (0, 160, 160, 3)\n",
    "image_target_shape = (160, 160)\n",
    "training_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS_COUNT):\n",
    "    t = time.time()\n",
    "    for batch in range(len(training_path)//BATCH_SIZE):\n",
    "        anchor_imgs = np.empty(image_input_shape)\n",
    "        pos_imgs = np.empty(image_input_shape)\n",
    "        neg_imgs = np.empty(image_input_shape)\n",
    "        start = batch * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        # print(\"    Batch from \" + str(start) + \" to \" + str(end))\n",
    "        for i in range (start, end):\n",
    "            anchor_path, pos_path, neg_path = training_path[i]\n",
    "            #print(anchor_path)\n",
    "            anchor_img = image.load_img(anchor_path, target_size=image_target_shape)\n",
    "            anchor_img = image.img_to_array(anchor_img)\n",
    "            #print(anchor_imgs.shape)\n",
    "            anchor_img = np.expand_dims(anchor_img, axis=0)\n",
    "            #print(anchor_imgs.shape)\n",
    "            anchor_img = preprocess_input(anchor_img)\n",
    "            anchor_imgs = np.append(anchor_imgs, anchor_img, axis=0)\n",
    "            #print(anchor_img.shape)\n",
    "\n",
    "            #print(test_path)\n",
    "            pos_img = image.load_img(pos_path, target_size=image_target_shape)\n",
    "            pos_img = image.img_to_array(pos_img)\n",
    "            pos_img = np.expand_dims(pos_img, axis=0)\n",
    "            pos_img = preprocess_input(pos_img)\n",
    "            pos_imgs = np.append(pos_imgs, pos_img, axis=0)\n",
    "            #print(pos_img.shape)\n",
    "\n",
    "            neg_img = image.load_img(neg_path, target_size=image_target_shape)\n",
    "            neg_img = image.img_to_array(neg_img)\n",
    "            neg_img = np.expand_dims(neg_img, axis=0)\n",
    "            neg_img = preprocess_input(neg_img)\n",
    "            neg_imgs = np.append(neg_imgs, neg_img, axis=0)\n",
    "            #print(neg_img.shape)\n",
    "\n",
    "        # dummy output, needed for being able to run the fit(..) function\n",
    "        z = np.zeros(BATCH_SIZE)\n",
    "        # print(len(z))\n",
    "        siamese_facenet.fit(x=[anchor_imgs, pos_imgs, neg_imgs], \n",
    "                    y=z, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=1, \n",
    "                    verbose=2, \n",
    "                    callbacks=None, \n",
    "                    validation_split=0.0, \n",
    "                    validation_data=None, \n",
    "                    shuffle=True, \n",
    "                    class_weight=None, \n",
    "                    sample_weight=None, \n",
    "                    initial_epoch=0, \n",
    "                    steps_per_epoch=None, \n",
    "                    validation_steps=None)\n",
    "        training_loss.append(siamese_facenet.history.history['loss'])\n",
    "    \n",
    "    print(\"Epoch : \" + str(epoch) + \" Time taken : \" + str(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training completed at this point. Save the model architecture and weights.\n",
    "# Save the Siamese FaceNet Network architecture\n",
    "siamese_model_json = siamese_facenet.to_json()\n",
    "with open(PATH_TRAIN_FACENET + \"/siamese_facenet_arch.json\", \"w\") as json_file:\n",
    "    json_file.write(siamese_model_json)\n",
    "# save the Siamese Network model weights\n",
    "siamese_facenet.save_weights(PATH_TRAIN_FACENET + \"/siamese_facenet_weights.h5\")\n",
    "\n",
    "# create and save the Encoding Network to use in predictions later on\n",
    "encoding_input = Input(shape=(160, 160, 3), name='facenet_encoding_input')\n",
    "encoding_output = new_model(encoding_input)\n",
    "encoding_facenet = Model(inputs  = encoding_input, outputs = encoding_output)\n",
    "\n",
    "weights = siamese_facenet.get_layer('model_1').get_weights()\n",
    "siamese_facenet.get_layer('model_1').set_weights(weights)\n",
    "\n",
    "# Save the Encoding Network architecture\n",
    "encoding_model_json = encoding_facenet.to_json()\n",
    "with open(PATH_TRAIN_FACENET + \"/encoding_facenet_arch.json\", \"w\") as json_file:\n",
    "    json_file.write(encoding_model_json)\n",
    "# save the Encoding Network model weights    \n",
    "encoding_facenet.save_weights(PATH_TRAIN_FACENET + '/encoding_facenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d1fad7c50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
