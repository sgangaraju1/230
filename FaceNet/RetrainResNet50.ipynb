{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Lambda, Input\n",
    "from keras.models import load_model, Model, model_from_json\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_FNAME   = \"lfw_datasets_and_models.zip\"\n",
    "\n",
    "PATH_INPUTS_FNAME     = \"./lfw_datasets_and_models.zip\" \n",
    "PATH_INPUTS           = \"/Users/vibhs/test/lfw_datasets_and_models\"\n",
    "\n",
    "PATH_DATASET_BASE     = PATH_INPUTS + \"/datasets\"\n",
    "\n",
    "PATH_DATASET_BASE_MASKED   = PATH_DATASET_BASE + \"/masked\"\n",
    "PATH_DATASET_BASE_UNMASKED = PATH_DATASET_BASE + \"/unmasked\"\n",
    "\n",
    "PATH_DATASET_MASKED_TRAIN = PATH_DATASET_BASE_MASKED + \"/train/\"\n",
    "PATH_DATASET_MASKED_VAL   = PATH_DATASET_BASE_MASKED + \"/validation/\"\n",
    "PATH_DATASET_MASKED_TEST  = PATH_DATASET_BASE_MASKED + \"/test/\"\n",
    "\n",
    "PATH_DATASET_UNMASKED_TRAIN = PATH_DATASET_BASE_UNMASKED + \"/train/\"\n",
    "PATH_DATASET_UNMASKED_VAL   = PATH_DATASET_BASE_UNMASKED + \"/validation/\"\n",
    "PATH_DATASET_UNMASKED_TEST  = PATH_DATASET_BASE_UNMASKED + \"/test/\"\n",
    "\n",
    "PATH_TRAIN_RESNET = PATH_INPUTS + '/models/resnet'\n",
    "PATH_TRAIN_FACENET = PATH_INPUTS + '/models/facenet'\n",
    "\n",
    "PATH_FACENET_KERAS_H5 = PATH_INPUTS + \"/models/facenet/keras-facenet/model/facenet_keras.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zipfile(filename: str, extract_dirname: str, extract_path: str):\n",
    "    # Extract the inputs from the zip file.\n",
    "    if (not os.path.isdir(extract_dirname)):\n",
    "        print(\"[INFO] Extracting from '{}' to '../'...\".format(filename), end=\" \")\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"DONE.\")\n",
    "    else:\n",
    "        print(\"[INFO] Directory '{}' exists.\".format(extract_dirname))\n",
    "\n",
    "#extract_zipfile(PATH_INPUTS_FNAME, PATH_INPUTS, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "TRAINING_IMAGES_COUNT = 34\n",
    "\n",
    "masked_path = []\n",
    "masked_dict = {}\n",
    "unmasked_path = []\n",
    "training_path = []\n",
    "for subdir in os.listdir(PATH_DATASET_MASKED_TRAIN):\n",
    "    filenames = os.listdir(PATH_DATASET_MASKED_TRAIN + subdir)\n",
    "    filename = PATH_DATASET_MASKED_TRAIN + subdir + \"/\" + filenames[0]\n",
    "    masked_path.append((subdir, filename))\n",
    "    masked_dict[subdir] = filename\n",
    "\n",
    "for subdir in os.listdir(PATH_DATASET_UNMASKED_TRAIN):\n",
    "    filenames = os.listdir(PATH_DATASET_UNMASKED_TRAIN + subdir)\n",
    "    filename = PATH_DATASET_UNMASKED_TRAIN + subdir + \"/\" + filenames[0]\n",
    "    unmasked_path.append((subdir, filename))\n",
    "\n",
    "print(len(masked_path))\n",
    "print(len(unmasked_path))\n",
    "\n",
    "masked_count = len(masked_path)\n",
    "unmasked_count = len(unmasked_path)\n",
    "neg = np.random.randint(masked_count, size=unmasked_count)\n",
    "for i in range(TRAINING_IMAGES_COUNT):\n",
    "    a_name, a_path = unmasked_path[i]\n",
    "    if a_name not in masked_dict:\n",
    "        continue\n",
    "    pos_path = masked_dict[a_name]\n",
    "    if (a_name != masked_path[neg[i]][0]):\n",
    "        neg_path = masked_path[neg[i]][1]\n",
    "    else:\n",
    "        neg_path = masked_path[neg[i+1]][1]\n",
    "    training_path.append((a_path, pos_path, neg_path))\n",
    "        \n",
    "print(len(training_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraing]\n",
    "def triplet_loss(inputs, dist='euclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, 1.8 + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(1 + K.exp(loss))\n",
    "        \n",
    "    returned_loss = K.mean(loss)\n",
    "    return returned_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "# Used when compiling the siamese network\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)  # This is actually just returning y_pred bcs\n",
    "                                        # K.mean has already been called in the triplet_loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "model = ResNet50(weights='imagenet')\n",
    "print(len(model.layers))\n",
    "model.layers.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_count = len(model.layers)\n",
    "for i in range(layers_count):\n",
    "    layer = model.layers[i]\n",
    "    if i < layers_count//2:\n",
    "        layer.trainable = False # Freeze first half of layers.\n",
    "    elif layer.trainable and not layer.name.startswith(\"bn\"):\n",
    "        layer.trainable = False # Leave all BatchNorm layers to retrain.\n",
    "\n",
    "last_layer = model.layers[layers_count - 1]\n",
    "last_layer.trainable = True # Mark last layer to retrain.\n",
    "\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer.name + \" : \" + str(layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Retraining]\n",
    "# Define the siamese ResNet network\n",
    "\n",
    "image_shape = (224, 224, 3)\n",
    "\n",
    "x = last_layer.output\n",
    "model_out = Dense(128, activation='relu',  name='model_out')(x)\n",
    "model_out = Lambda(lambda  x: K.l2_normalize(x, axis=-1))(model_out)\n",
    "\n",
    "new_model = Model(inputs=model.input, outputs=model_out)\n",
    "\n",
    "anchor_input = Input(shape=image_shape, name='anchor_input')\n",
    "pos_input = Input(shape=image_shape, name='pos_input')\n",
    "neg_input = Input(shape=image_shape, name='neg_input')\n",
    "\n",
    "encoding_anchor = new_model(anchor_input)\n",
    "encoding_pos = new_model(pos_input)\n",
    "encoding_neg = new_model(neg_input)\n",
    "\n",
    "loss = Lambda(triplet_loss)([encoding_anchor, encoding_pos, encoding_neg])\n",
    "\n",
    "siamese_model = Model(inputs  = [anchor_input, pos_input, neg_input], outputs = loss)\n",
    "siamese_model.compile(optimizer=Adam(lr=.05, clipnorm=1.), loss=identity_loss)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_COUNT = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "image_input_shape = (0, 224, 224, 3)\n",
    "image_target_shape = (224, 224)\n",
    "training_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS_COUNT):\n",
    "    t = time.time()\n",
    "    for batch in range(len(training_path)//BATCH_SIZE):\n",
    "        anchor_imgs = np.empty(image_input_shape)\n",
    "        pos_imgs = np.empty(image_input_shape)\n",
    "        neg_imgs = np.empty(image_input_shape)\n",
    "        start = batch * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        # print(\"    Batch from \" + str(start) + \" to \" + str(end))\n",
    "        for i in range (start, end):\n",
    "            anchor_path, pos_path, neg_path = training_path[i]\n",
    "            #print(anchor_path)\n",
    "            anchor_img = image.load_img(anchor_path, target_size=image_target_shape)\n",
    "            anchor_img = image.img_to_array(anchor_img)\n",
    "            #print(anchor_imgs.shape)\n",
    "            anchor_img = np.expand_dims(anchor_img, axis=0)\n",
    "            #print(anchor_imgs.shape)\n",
    "            anchor_img = preprocess_input(anchor_img)\n",
    "            anchor_imgs = np.append(anchor_imgs, anchor_img, axis=0)\n",
    "            #print(anchor_img.shape)\n",
    "\n",
    "            #print(test_path)\n",
    "            pos_img = image.load_img(pos_path, target_size=image_target_shape)\n",
    "            pos_img = image.img_to_array(pos_img)\n",
    "            pos_img = np.expand_dims(pos_img, axis=0)\n",
    "            pos_img = preprocess_input(pos_img)\n",
    "            pos_imgs = np.append(pos_imgs, pos_img, axis=0)\n",
    "            #print(pos_img.shape)\n",
    "\n",
    "            neg_img = image.load_img(neg_path, target_size=image_target_shape)\n",
    "            neg_img = image.img_to_array(neg_img)\n",
    "            neg_img = np.expand_dims(neg_img, axis=0)\n",
    "            neg_img = preprocess_input(neg_img)\n",
    "            neg_imgs = np.append(neg_imgs, neg_img, axis=0)\n",
    "            #print(neg_img.shape)\n",
    "\n",
    "        # dummy output, needed for being able to run the fit(..) function\n",
    "        z = np.zeros(BATCH_SIZE)\n",
    "        # print(len(z))\n",
    "        siamese_model.fit(x=[anchor_imgs, pos_imgs, neg_imgs], \n",
    "                    y=z, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=1, \n",
    "                    verbose=2, \n",
    "                    callbacks=None, \n",
    "                    validation_split=0.0, \n",
    "                    validation_data=None, \n",
    "                    shuffle=True, \n",
    "                    class_weight=None, \n",
    "                    sample_weight=None, \n",
    "                    initial_epoch=0, \n",
    "                    steps_per_epoch=None, \n",
    "                    validation_steps=None)\n",
    "        training_loss.append(siamese_model.history.history['loss'])\n",
    "    \n",
    "    print(\"Epoch : \" + str(epoch) + \" Time taken : \" + str(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training completed at this point. Save the model architecture and weights.\n",
    "# Save the Siamese ResNet50 Network architecture\n",
    "siamese_model_json = siamese_model.to_json()\n",
    "with open(PATH_TRAIN_RESNET + \"/siamese_resnet_arch.json\", \"w\") as json_file:\n",
    "    json_file.write(siamese_model_json)\n",
    "# save the Siamese Network model weights\n",
    "siamese_model.save_weights(PATH_TRAIN_RESNET + \"/siamese_resnet_weights.h5\")\n",
    "\n",
    "# create and save the Encoding Network to use in predictions later on\n",
    "encoding_input = Input(shape=(160, 160, 3), name='resnet_encoding_input')\n",
    "encoding_output = new_model(encoding_input)\n",
    "encoding_resnet = Model(inputs  = encoding_input, outputs = encoding_output)\n",
    "\n",
    "weights = siamese_model.get_layer('model_1').get_weights()\n",
    "siamese_model.get_layer('model_1').set_weights(weights)\n",
    "\n",
    "# Save the Encoding Network architecture\n",
    "encoding_model_json = encoding_resnet.to_json()\n",
    "with open(PATH_TRAIN_RESNET + \"/encoding_resnet_arch.json\", \"w\") as json_file:\n",
    "    json_file.write(encoding_model_json)\n",
    "# save the Encoding Network model weights    \n",
    "encoding_resnet.save_weights(PATH_TRAIN_RESNET + '/encoding_resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
